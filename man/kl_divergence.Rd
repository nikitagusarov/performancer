% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kl_divergence.R
\name{kl_divergence}
\alias{kl_divergence}
\title{Kullback–Leibler Divergence (KLD)}
\usage{
kl_divergence(y_real, y_predicted)
}
\arguments{
\item{y_real}{Observed values (integers) to compare with
(in matrix format for multiclass classification).}

\item{y_predicted}{Predicte values (probabiblities by class).}
}
\value{
integer value of Kullback–Leibler Divergence (KLD)
}
\description{
Compute Kullback–Leibler Divergence (KLD) using confusion matrix.
KL divergence basically just finds the difference between the entropies of the two distributions `P(y|f)` and `p(y)`.
}
